
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="LooperXX's homepage">
      
      
      
        <meta name="author" content="Looper - Xiao Xu">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.0.2">
    
    
      
        <title>11 ConvNets for NLP - Science is interesting.</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.38780c08.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f72e892.min.css">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
        
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-164217558-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="preference" data-md-color-primary="" data-md-color-accent="">
      
        <script>matchMedia("(prefers-color-scheme: dark)").matches&&document.body.setAttribute("data-md-color-scheme","slate")</script>
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lecture-11-convnets-for-nlp" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="Science is interesting." class="md-header-nav__button md-logo" aria-label="Science is interesting.">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Science is interesting.
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              11 ConvNets for NLP
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/LooperXX/LooperXX.github.io/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    LooperXX/LooperXX.github.io
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          

  

<nav class="md-tabs md-tabs--active" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." class="md-tabs__link">
        Homepage
      </a>
    
  </li>

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../Attention/" class="md-tabs__link">
          Notes
        </a>
      
    </li>
  

  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../CS224n-2019%20%E7%AE%80%E4%BB%8B/" class="md-tabs__link md-tabs__link--active">
          Notes on CS224n
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../MkDocs_demo/" class="md-tabs__link">
          For MkDocs
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Science is interesting." class="md-nav__button md-logo" aria-label="Science is interesting.">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Science is interesting.
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/LooperXX/LooperXX.github.io/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    LooperXX/LooperXX.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." class="md-nav__link">
      Homepage
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Notes
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Notes" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        Notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2-1" type="checkbox" id="nav-2-1">
    
    <label class="md-nav__link" for="nav-2-1">
      Theory
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Theory" data-md-level="2">
      <label class="md-nav__title" for="nav-2-1">
        <span class="md-nav__icon md-icon"></span>
        Theory
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Attention/" class="md-nav__link">
      Attention
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Normalization/" class="md-nav__link">
      Normalization
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2">
    
    <label class="md-nav__link" for="nav-2-2">
      Code
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Code" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        <span class="md-nav__icon md-icon"></span>
        Code
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Notes%20on%20NCRF%2B%2B/" class="md-nav__link">
      NCRF++
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2-3" type="checkbox" id="nav-2-3">
    
    <label class="md-nav__link" for="nav-2-3">
      Book
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Book" data-md-level="2">
      <label class="md-nav__title" for="nav-2-3">
        <span class="md-nav__icon md-icon"></span>
        Book
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Neural%20Reading%20Comprehension%20and%20beyond/" class="md-nav__link">
      Machine Reading Comprehension
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../NLP%20Concepts/" class="md-nav__link">
      Some Concepts
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../NNDL%20exercise/" class="md-nav__link">
      NNDL exercise
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Notes on CS224n
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Notes on CS224n" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Notes on CS224n
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019%20%E7%AE%80%E4%BB%8B/" class="md-nav__link">
      CS224n-2019 Introduction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-Assignment/" class="md-nav__link">
      CS224n-2019 Assignment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-01-Introduction%20and%20Word%20Vectors/" class="md-nav__link">
      01 Introduction and Word Vectors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-02-Word%20Vectors%202%20and%20Word%20Senses/" class="md-nav__link">
      02 Word Vectors 2 and Word Senses
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-03-Word%20Window%20Classification%2CNeural%20Networks%2C%20and%20Matrix%20Calculus/" class="md-nav__link">
      03 Word Window Classification,Neural Networks, and Matrix Calculus
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-04-Backpropagation%20and%20Computation%20Graphs/" class="md-nav__link">
      04 Backpropagation and Computation Graphs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-05-Linguistic%20Structure%20Dependency%20Parsing/" class="md-nav__link">
      05 Linguistic Structure Dependency Parsing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-06-The%20probability%20of%20a%20sentence%20Recurrent%20Neural%20Networks%20and%20Language%20Models/" class="md-nav__link">
      06 The probability of a sentence Recurrent Neural Networks and Language Models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-07-Vanishing%20Gradients%20and%20Fancy%20RNNs/" class="md-nav__link">
      07 Vanishing Gradients and Fancy RNNs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-08-Machine%20Translation%2C%20Sequence-to-sequence%20and%20Attention/" class="md-nav__link">
      08 Machine Translation, Sequence-to-sequence and Attention
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-09-Practical%20Tips%20for%20Final%20Projects/" class="md-nav__link">
      09 Practical Tips for Final Projects
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-10-Question%20Answering%20and%20the%20Default%20Final%20Project/" class="md-nav__link">
      10 Question Answering and the Default Final Project
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        11 ConvNets for NLP
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      11 ConvNets for NLP
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-11-convnets-for-nlp" class="md-nav__link">
    Lecture 11 ConvNets for NLP
  </a>
  
    <nav class="md-nav" aria-label="Lecture 11 ConvNets for NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2-from-rnns-to-convolutional-neural-nets" class="md-nav__link">
    2. From RNNs to Convolutional Neural Nets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-single-layer-cnn-for-sentence-classification" class="md-nav__link">
    3. Single Layer CNN for Sentence Classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-model-comparison-our-growing-toolkit" class="md-nav__link">
    4. Model comparison: Our growing toolkit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-very-deep-convolutional-networks-for-text-classification" class="md-nav__link">
    5. Very Deep Convolutional Networks for Text Classification
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes-08-convolutional-neural-networks" class="md-nav__link">
    Notes 08 Convolutional Neural Networks
  </a>
  
    <nav class="md-nav" aria-label="Notes 08 Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cnns-convolutional-neural-networks" class="md-nav__link">
    1 CNNs (Convolutional Neural Networks)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-a-single-layer-cnn" class="md-nav__link">
    1.3 A Single-Layer CNN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" class="md-nav__link">
    Reference
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-12-Information%20from%20parts%20of%20words%20Subword%20Models/" class="md-nav__link">
      12 Information from parts of words Subword Models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-13-Modeling%20contexts%20of%20use%20Contextual%20Representations%20and%20Pretraining/" class="md-nav__link">
      13 Modeling contexts of use Contextual Representations and Pretraining
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-14-Transformers%20and%20Self-Attention%20For%20Generative%20Models/" class="md-nav__link">
      14 Transformers and Self-Attention For Generative Models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-15-Natural%20Language%20Generation/" class="md-nav__link">
      15 Natural Language Generation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-16-Coreference%20Resolution/" class="md-nav__link">
      16 Coreference Resolution
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-17-Multitask%20Learning/" class="md-nav__link">
      17 Multitask Learning
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-18-Tree%20Recursive%20Neural%20Networks%2C%20Constituency%20Parsing%2C%20and%20Sentiment/" class="md-nav__link">
      18 Tree Recursive Neural Networks, Constituency Parsing, and Sentiment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-19-Safety%2C%20Bias%2C%20and%20Fairness/" class="md-nav__link">
      19 Safety, Bias, and Fairness
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../CS224n-2019-20-The%20Future%20of%20NLP%20%2B%20Deep%20Learning/" class="md-nav__link">
      20 The Future of NLP + Deep Learning
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      For MkDocs
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="For MkDocs" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        For MkDocs
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../MkDocs_demo/" class="md-nav__link">
      Demo
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Material%20Theme%20Tutorial/" class="md-nav__link">
      Material Theme Tutorial
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lecture-11-convnets-for-nlp" class="md-nav__link">
    Lecture 11 ConvNets for NLP
  </a>
  
    <nav class="md-nav" aria-label="Lecture 11 ConvNets for NLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2-from-rnns-to-convolutional-neural-nets" class="md-nav__link">
    2. From RNNs to Convolutional Neural Nets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-single-layer-cnn-for-sentence-classification" class="md-nav__link">
    3. Single Layer CNN for Sentence Classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-model-comparison-our-growing-toolkit" class="md-nav__link">
    4. Model comparison: Our growing toolkit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-very-deep-convolutional-networks-for-text-classification" class="md-nav__link">
    5. Very Deep Convolutional Networks for Text Classification
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes-08-convolutional-neural-networks" class="md-nav__link">
    Notes 08 Convolutional Neural Networks
  </a>
  
    <nav class="md-nav" aria-label="Notes 08 Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cnns-convolutional-neural-networks" class="md-nav__link">
    1 CNNs (Convolutional Neural Networks)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-a-single-layer-cnn" class="md-nav__link">
    1.3 A Single-Layer CNN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reference" class="md-nav__link">
    Reference
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/LooperXX/LooperXX.github.io/edit/master/docs/CS224n-2019-11-ConvNets for NLP.md" title="编辑此页" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>11 ConvNets for NLP</h1>
                
                <h2 id="lecture-11-convnets-for-nlp">Lecture 11 ConvNets for NLP<a class="headerlink" href="#lecture-11-convnets-for-nlp" title="Permanent link">&para;</a></h2>
<p><strong>Lecture Plan</strong></p>
<ol>
<li>Announcements</li>
<li>Intro to CNNs</li>
<li>Simple CNN for Sentence Classification: Yoon (2014)</li>
<li>CNN potpourri </li>
<li>Deep CNN for Sentence Classification: Conneauet al. (2017) </li>
<li>Quasi-recurrent Neural Networks </li>
</ol>
<p><strong>Welcome to the second half of the course!</strong> </p>
<ul>
<li>现在，我们正在为您准备成为DL+NLP研究人员/实践者</li>
<li>讲座不会总是有所有的细节<ul>
<li>这取决于你在网上搜索/阅读来了解更多</li>
<li>这是一个活跃的研究领域，有时候没有明确的答案</li>
<li>Staff 很乐意与你讨论，但你需要自己思考</li>
</ul>
</li>
<li>作业的设计是为了应付项目的真正困难<ul>
<li>每个任务都故意比上一个任务有更少的帮助材料。</li>
<li>在项目中，没有提供 autograder 或 合理性检查</li>
<li>DL调试很困难，但是您需要学习如何进行调试！</li>
</ul>
</li>
</ul>
<p><strong>Wanna read a book?</strong></p>
<p><img alt="1561454729585" src="../imgs/1561454729585.png" /></p>
<h3 id="2-from-rnns-to-convolutional-neural-nets">2. From RNNs to Convolutional Neural Nets<a class="headerlink" href="#2-from-rnns-to-convolutional-neural-nets" title="Permanent link">&para;</a></h3>
<ul>
<li>递归神经网络不能捕获没有前缀上下文的短语</li>
<li>经常在最终向量中捕获太多的最后单词</li>
</ul>
<p><img alt="1561454792548" src="../imgs/1561454792548.png" /></p>
<ul>
<li>例如，softmax通常只在最后一步计算</li>
</ul>
<p><strong>From RNNs to Convolutional Neural Nets</strong> </p>
<ul>
<li>卷积网络的主要想法：</li>
<li>如果我们为每个可能的子序列计算一定长度的向量呢？</li>
<li>例如：“tentative deal reached to keep government open” 计算的向量为<ul>
<li>tentative deal reached, deal reached to, reached to keep, to keep government, keep government open</li>
</ul>
</li>
<li>不管短语是否合乎语法</li>
<li>在语言学上或认知上不太可信</li>
<li>然后将它们分组(很快)</li>
</ul>
<p><strong>What is a convolution anyway?</strong> </p>
<ul>
<li>一维离散卷积一般为： <span><span class="MathJax_Preview">(f * g)[n]=\sum_{m=-M}^{M} f[n-m] g[m]</span><script type="math/tex">(f * g)[n]=\sum_{m=-M}^{M} f[n-m] g[m]</script></span></li>
<li>卷积经典地用于从图像中提取特征<ul>
<li>模型位置不变的识别</li>
<li>转到cs231n！</li>
</ul>
</li>
<li>2d example </li>
</ul>
<p><img alt="1561454980925" src="../imgs/1561454980925.png" /></p>
<ul>
<li>黄色和红色数字显示过滤器(=内核)权重</li>
<li>绿色显示输入</li>
<li>粉色显示输出</li>
</ul>
<p><strong>A 1D convolution for text</strong></p>
<p><img alt="1561455061952" src="../imgs/1561455061952.png" /></p>
<p><strong>1D convolution for text with padding</strong></p>
<p><img alt="1561455077841" src="../imgs/1561455077841.png" /></p>
<ul>
<li>输入长度为 <span><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span> 的词序列，假设单词维度为 4，即有 4 channels</li>
<li>卷积后将会得到 1 channel</li>
</ul>
<p><strong>3 channel 1D convolution with padding = 1</strong></p>
<p><img alt="1561455099634" src="../imgs/1561455099634.png" /></p>
<ul>
<li>多个channel则最终得到多个channel的输出，关注的文本潜在特征也不同</li>
</ul>
<p><strong>conv1d, padded with max pooling over time</strong></p>
<p><img alt="1561455221087" src="../imgs/1561455221087.png" /></p>
<ul>
<li>通过 max pooling over time，获得最大的激活值</li>
</ul>
<p><strong>conv1d, padded with avepooling over time</strong></p>
<p><img alt="1561455253576" src="../imgs/1561455253576.png" /></p>
<p><strong>In PyTorch</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span><span class="o">=</span> <span class="mi">16</span> 
<span class="n">word_embed_size</span><span class="o">=</span> <span class="mi">4</span> 
<span class="n">seq_len</span><span class="o">=</span> <span class="mi">7</span> 
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">word_embed_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span> 
<span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">word_embed_size</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># can add: padding=1 </span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">hidden2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">hidden1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># max pool</span>
</code></pre></div>
<p><strong>Other less useful notions: stride = 2</strong></p>
<p><img alt="1561455353605" src="../imgs/1561455353605.png" /></p>
<ul>
<li>stride 步长，减少计算量</li>
</ul>
<p><strong>Less useful: local max pool, stride = 2</strong></p>
<p><img alt="1561455385947" src="../imgs/1561455385947.png" /></p>
<ul>
<li>每两行做 max pooling，被称为步长为2的局部最大池化</li>
</ul>
<p><strong>conv1d, k-max pooling over time, k= 2</strong></p>
<p><img alt="1561455408838" src="../imgs/1561455408838.png" /></p>
<ul>
<li>记录每一个channel的所有时间的 top k的激活值，并且按原有顺序保留（上例中的-0.2 0.3）</li>
</ul>
<p><strong>Other somewhat useful notions: dilation = 2</strong></p>
<p><img alt="1561455422905" src="../imgs/1561455422905.png" /></p>
<ul>
<li>扩张卷积</li>
<li>上例中，对1 3 5行进行卷积，通过两个filter得到两个channel的激活值</li>
<li>可以在第一步的卷积中将卷积核从3改为5，即可实现这样的效果，既保证了矩阵很小，又保证了一次卷积中看到更大范围的句子</li>
</ul>
<p>Summary</p>
<ul>
<li>在CNN中，一次能看一个句子的多少内容是很重要的概念</li>
<li>可以使用更大的filter、扩张卷积或者增大卷积深度（层数）</li>
</ul>
<h3 id="3-single-layer-cnn-for-sentence-classification">3. Single Layer CNN for Sentence Classification<a class="headerlink" href="#3-single-layer-cnn-for-sentence-classification" title="Permanent link">&para;</a></h3>
<ul>
<li>Yoon Kim (2014): Convolutional Neural Networks for Sentence Classification. EMNLP 2014. <a href="https://arxiv.org/pdf/1408.5882.pdf">https://arxiv.org/pdf/1408.5882.pdf</a> Code: <a href="https://arxiv.org/pdf/1408.5882.pdf[Theano">https://arxiv.org/pdf/1408.5882.pdf[Theano</a>!, etc.]</li>
<li>A variant of convolutional NNs of Collobert, Weston et al. (2011) </li>
<li>目标：句子分类<ul>
<li>主要是句子的积极或消极情绪</li>
<li>其他任务<ul>
<li>判断句子主观或客观</li>
<li>问题分类：问题是关于什么实体的？关于人、地点、数字、……</li>
</ul>
</li>
</ul>
</li>
<li>一个卷积层和池化层的简单使用</li>
<li>词向量：<span><span class="MathJax_Preview">\mathbf{x}_{i} \in \mathbb{R}^{k}</span><script type="math/tex">\mathbf{x}_{i} \in \mathbb{R}^{k}</script></span></li>
<li>句子：<span><span class="MathJax_Preview">\mathbf{x}_{1 : n}=\mathbf{x}_{1} \oplus x_{2} \oplus \cdots \oplus \mathbf{x}_{n}</span><script type="math/tex">\mathbf{x}_{1 : n}=\mathbf{x}_{1} \oplus x_{2} \oplus \cdots \oplus \mathbf{x}_{n}</script></span> (向量连接)</li>
<li>连接 <span><span class="MathJax_Preview">\mathbf{X}_{i : i+j}</span><script type="math/tex">\mathbf{X}_{i : i+j}</script></span> 范围内的句子 (对称更常见)</li>
<li>卷积核 <span><span class="MathJax_Preview">\mathbf{w} \in \mathbb{R}^{h k}</span><script type="math/tex">\mathbf{w} \in \mathbb{R}^{h k}</script></span> (作用范围为 h 个单词的窗口)</li>
<li>注意，filter是向量，size  可以是2,3或4</li>
</ul>
<p><strong>Single layer CNN</strong></p>
<ul>
<li>
<p>过滤器 <span><span class="MathJax_Preview">\boldsymbol w</span><script type="math/tex">\boldsymbol w</script></span> 应用于所有可能的窗口(连接向量)</p>
</li>
<li>
<p>为CNN层计算特征(一个通道)</p>
</li>
</ul>
<div>
<div class="MathJax_Preview">
c_{i}=f\left(\mathbf{w}^{T} \mathbf{x}_{i : i+h-1}+b\right)
</div>
<script type="math/tex; mode=display">
c_{i}=f\left(\mathbf{w}^{T} \mathbf{x}_{i : i+h-1}+b\right)
</script>
</div>
<ul>
<li>句子 <span><span class="MathJax_Preview">\mathbf{x}_{1 : n}=\mathbf{x}_{1} \oplus \mathbf{x}_{2} \oplus \ldots \oplus \mathbf{x}_{n}</span><script type="math/tex">\mathbf{x}_{1 : n}=\mathbf{x}_{1} \oplus \mathbf{x}_{2} \oplus \ldots \oplus \mathbf{x}_{n}</script></span></li>
<li>所有可能的长度为 h 的窗口 <span><span class="MathJax_Preview">\left\{\mathbf{x}_{1 : h}, \mathbf{x}_{2 : h+1}, \dots, \mathbf{x}_{n-h+1 : n}\right\}</span><script type="math/tex">\left\{\mathbf{x}_{1 : h}, \mathbf{x}_{2 : h+1}, \dots, \mathbf{x}_{n-h+1 : n}\right\}</script></span></li>
<li>结果是一个 feature map <span><span class="MathJax_Preview">\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}</span><script type="math/tex">\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}</script></span></li>
</ul>
<p><img alt="1561455820959" src="../imgs/1561455820959.png" /></p>
<p><strong>Pooling and channels</strong></p>
<ul>
<li>池化：max-over-time pooling layer</li>
<li>想法：捕获最重要的激活(maximum over time)</li>
<li>从feature map中 <span><span class="MathJax_Preview">\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}</span><script type="math/tex">\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}</script></span></li>
<li>池化得到单个数字 <span><span class="MathJax_Preview">\hat{c}=\max \{\mathbf{c}\}</span><script type="math/tex">\hat{c}=\max \{\mathbf{c}\}</script></span></li>
<li>使用多个过滤器权重 <span><span class="MathJax_Preview">\boldsymbol{w}</span><script type="math/tex">\boldsymbol{w}</script></span> </li>
<li>不同窗口大小 h 是有用的</li>
<li>由于最大池化 <span><span class="MathJax_Preview">\hat{c}=\max \{\mathbf{c}\}</span><script type="math/tex">\hat{c}=\max \{\mathbf{c}\}</script></span> ，和 <span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span> 的长度无关</li>
</ul>
<div>
<div class="MathJax_Preview">
\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}
</div>
<script type="math/tex; mode=display">
\mathbf{c}=\left[c_{1}, c_{2}, \dots, c_{n-h+1}\right] \in \mathbb{R}^{n-h+1}
</script>
</div>
<ul>
<li>所以我们可以有一些 filters 来观察 unigrams, bigrams, tri-grams, 4-grams,等等</li>
</ul>
<p><strong>Multi-channel input idea</strong> </p>
<ul>
<li>使用预先训练的单词向量初始化(word2vec或Glove)</li>
<li>从两个副本开始</li>
<li>只有一个副本进行了反向传播，保持其他“静态”</li>
<li>两个通道集都在最大池化前添加到 <span><span class="MathJax_Preview">c_i</span><script type="math/tex">c_i</script></span></li>
</ul>
<p><strong>Classification after one CNN layer</strong> </p>
<ul>
<li>首先是一个卷积，然后是一个最大池化</li>
<li>为了获得最终的特征向量 <span><span class="MathJax_Preview">\mathbf{z}=\left[\hat{c}_{1}, \dots, \hat{c}_{m}\right]</span><script type="math/tex">\mathbf{z}=\left[\hat{c}_{1}, \dots, \hat{c}_{m}\right]</script></span><ul>
<li>假设我们有 m 个 filter <span><span class="MathJax_Preview">\mathbf{w}</span><script type="math/tex">\mathbf{w}</script></span></li>
<li>使用100个大小分别为3、4、5的特征图</li>
</ul>
</li>
<li>最终是简单的 softmax layer <span><span class="MathJax_Preview">y=\operatorname{softmax}\left(W^{(S)} z+b\right)</span><script type="math/tex">y=\operatorname{softmax}\left(W^{(S)} z+b\right)</script></span></li>
</ul>
<p><img alt="1561474702080" src="../imgs/1561474702080.png" /></p>
<p><a href="https://arxiv.org/pdf/1510.03820.pdf">https://arxiv.org/pdf/1510.03820.pdf</a> </p>
<ul>
<li>输入长度为 7 的一句话，每个词的维度是 5 ，即输入矩阵是 <span><span class="MathJax_Preview">7 \times 5</span><script type="math/tex">7 \times 5</script></span></li>
<li>使用不同的filter_size : (2,3,4)，并且每个size都是用两个filter，获得两个channel的feature，即共计6个filter</li>
<li>对每个filter的feature进行1-max pooling后，拼接得到 6 维的向量，并使用softmax后再获得二分类结果</li>
</ul>
<p><strong>Regularization</strong></p>
<ul>
<li>使用 <strong>Dropout</strong> : 使用概率 p (超参数)的伯努利随机变量（只有0 1并且p是为1的概率）创建mask向量 r </li>
<li>训练过程中删除特征</li>
</ul>
<div>
<div class="MathJax_Preview">
y=\operatorname{softmax}\left(W^{(S)}(r \circ z)+b\right)
</div>
<script type="math/tex; mode=display">
y=\operatorname{softmax}\left(W^{(S)}(r \circ z)+b\right)
</script>
</div>
<ul>
<li>解释：防止互相适应(对特定特征的过度拟合)(Srivastava, Hinton, et al. 2014) </li>
<li>在测试时不适用dropout，使用概率p缩放最终向量</li>
</ul>
<div>
<div class="MathJax_Preview">
\hat{W}^{(S)}=p W^{(S)}
</div>
<script type="math/tex; mode=display">
\hat{W}^{(S)}=p W^{(S)}
</script>
</div>
<ul>
<li>此外：限制每个类的权重向量的L2 Norm(softmax 权重 <span><span class="MathJax_Preview">W^{(S)}</span><script type="math/tex">W^{(S)}</script></span> 的每一行)不超过固定数 <span><span class="MathJax_Preview">s</span><script type="math/tex">s</script></span> (也是超参数)</li>
<li>如果 <span><span class="MathJax_Preview">\left\|W_{c}^{(S)}\right\|&gt;s</span><script type="math/tex">\left\|W_{c}^{(S)}\right\|>s</script></span> ，则重新缩放为 <span><span class="MathJax_Preview">\left\|W_{c}^{(S)}\right\|=s</span><script type="math/tex">\left\|W_{c}^{(S)}\right\|=s</script></span><ul>
<li>不是很常见</li>
</ul>
</li>
</ul>
<p><strong>All hyperparametersin Kim (2014)</strong> </p>
<p><img alt="1561476833533" src="../imgs/1561476833533.png" /></p>
<p><strong>Problem with comparison?</strong></p>
<ul>
<li>Dropout提供了2 - 4%的精度改进</li>
<li>但几个比较系统没有使用Dropout，并可能从它获得相同的收益</li>
<li>仍然被视为一个简单架构的显著结果</li>
<li>与我们在前几节课中描述的窗口和RNN架构的不同之处：池化、许多过滤器和dropout</li>
<li>这些想法中有的可以被用在RNNs中</li>
</ul>
<h3 id="4-model-comparison-our-growing-toolkit">4. Model comparison: Our growing toolkit<a class="headerlink" href="#4-model-comparison-our-growing-toolkit" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Bag of Vectors</strong> ：对于简单的分类问题，这是一个非常好的基线。特别是如果后面有几个ReLU层(See paper: Deep Averaging Networks) </li>
<li><strong>Window Model</strong> ：对于不需要广泛上下文的问题（即适用于local问题），适合单字分类。例如POS, NER</li>
<li><strong>CNNs</strong> ：适合分类，较短的短语需要零填充，难以解释，易于在gpu上并行化</li>
<li><strong>RNNs</strong> ：从左到右的认知更加具有可信度，不适合分类(如果只使用最后一种状态)，比CNNs慢得多，适合序列标记和分类以及语言模型，结合注意力机制时非常棒</li>
</ul>
<p>RNN对序列标记和分类之类的事情有很好的效果，以及语言模型预测下一个单词，并且结合注意力机制会取得很好的效果，但是对于某个句子的整体解释，CNN做的是更好的</p>
<p><strong>Gated units used vertically</strong> </p>
<ul>
<li>我们在LSTMs和GRUs中看到的门/跳过是一个普遍的概念，现在在很多地方都使用这个概念</li>
<li>您还可以使用垂直的门</li>
<li>实际上，关键的概念——用快捷连接对候选更新求和——是非常深的网络工作所需要的</li>
</ul>
<p><img alt="1561477418175" src="../imgs/1561477418175.png" /></p>
<ul>
<li>Note: pad <span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span> for conv so same size when add them</li>
</ul>
<p><strong>Batch Normalization (BatchNorm)</strong></p>
<p>[Ioffeand Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv:1502.03167.] </p>
<ul>
<li>常用于 CNNs</li>
<li>通过将激活量缩放为零均值和单位方差，对一个mini-batch的卷积输出进行变换<ul>
<li>这是统计学中熟悉的 Z-transform </li>
<li>但在每组mini-batch都会更新，所以波动的影响不大</li>
</ul>
</li>
<li>使用BatchNorm使模型对参数初始化的敏感程度下降，因为输出是自动重新标度的<ul>
<li>也会让学习率的调优更简单</li>
<li>模型的训练会更加稳定</li>
</ul>
</li>
<li>PyTorch: nn.BatchNorm1d</li>
</ul>
<p><strong>1 x 1 Convolutions</strong></p>
<p>[Lin, Chen, and Yan. 2013. Network in network. arXiv:1312.4400.] </p>
<ul>
<li>这个概念有意义吗?是的</li>
<li>1x1卷积，即网络中的 Network-in-network (NiN) connections，是内核大小为1的卷积内核</li>
<li>1x1卷积为您提供了一个跨通道的全连接的线性层</li>
<li>它可以用于从多个通道映射到更少的通道</li>
<li>1x 1卷积添加了额外的神经网络层，附加的参数很少，<ul>
<li>与全连接(FC)层不同，全连接(FC)层添加了大量的参数</li>
</ul>
</li>
</ul>
<p><strong>CNN application: Translation</strong> </p>
<p><img alt="1561477856113" src="../imgs/1561477856113.png" /></p>
<ul>
<li>最早成功的神经机器翻译之一</li>
<li>使用CNN进行编码，使用RNN进行解码</li>
<li>Kalchbrennerand Blunsom(2013) “Recurrent Continuous Translation Models”</li>
</ul>
<p><strong>Learning Character-level Representations for Part-of-Speech Tagging</strong> </p>
<p>Dos Santos and Zadrozny(2014) </p>
<p><img alt="1561477964396" src="../imgs/1561477964396.png" /></p>
<ul>
<li>对字符进行卷积以生成单词嵌入</li>
<li>固定窗口的词嵌入被用于POS标签</li>
</ul>
<p><strong>Character-Aware Neural Language Models</strong> </p>
<p>(Kim, Jernite, Sontag, and Rush 2015) </p>
<p><img alt="1561477973684" src="../imgs/1561477973684.png" /></p>
<ul>
<li>基于字符的单词嵌入</li>
<li>利用卷积、highway network和LSTM</li>
</ul>
<h3 id="5-very-deep-convolutional-networks-for-text-classification">5. Very Deep Convolutional Networks for Text Classification<a class="headerlink" href="#5-very-deep-convolutional-networks-for-text-classification" title="Permanent link">&para;</a></h3>
<ul>
<li>Conneau, Schwenk, Lecun, Barrault. EACL 2017. </li>
<li>起始点：序列模型(LSTMs)在NLP中占主导地位；还有CNNs、注意力等等，但是所有的模型基本上都不是很深入——不像计算机视觉中的深度模型</li>
<li>当我们为NLP构建一个类似视觉的系统时会发生什么</li>
<li>从字符级开始工作</li>
</ul>
<p><img alt="1561478047400" src="../imgs/1561478047400.png" /></p>
<p><strong>Convolutional block in VD-CNN</strong></p>
<p><img alt="1561478059668" src="../imgs/1561478059668.png" /></p>
<ul>
<li>每个卷积块是两个卷积层，每个卷积层后面是BatchNorm和一个ReLU</li>
<li>卷积大小为3</li>
<li>pad 以保持(或在局部池化时减半)维数</li>
</ul>
<p><strong>Experiments</strong></p>
<ul>
<li>使用大文本分类数据集<ul>
<li>比NLP中经常使用的小数据集大得多，如Yoon Kim(2014)的论文</li>
</ul>
</li>
</ul>
<p><img alt="1561521266454" src="../imgs/1561521266454.png" /></p>
<ul>
<li>以上数据均为错误率，所以越低越好</li>
<li>深度网络会取得更好的结果，残差层取得很好的结果，但是深度再深时并未取得效果提升</li>
<li>实验表明使用 MaxPooling 比 KMaxPooling 和 使用stride的卷积 的两种其他池化方法要更好</li>
<li>ConvNets可以帮助我们建立很好的文本分类系统</li>
</ul>
<p><strong>6. RNNs are Slow …</strong> </p>
<ul>
<li>RNNs是深度NLP的一个非常标准的构建块</li>
<li>但它们的并行性很差，因此速度很慢</li>
<li>想法：取RNNs和CNNs中最好且可并行的部分</li>
<li>Quasi-Recurrent Neural Networks by James Bradbury, Stephen Merity, CaimingXiong&amp; Richard Socher. ICLR 2017</li>
</ul>
<p><strong>Quasi-Recurrent Neural Network</strong> </p>
<ul>
<li>努力把两个模型家族的优点结合起来</li>
</ul>
<p><img alt="1561478217493" src="../imgs/1561478217493.png" /></p>
<ul>
<li>时间上并行的卷积，卷积计算候选，遗忘门和输出门</li>
</ul>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf{z}_{t} &amp;=\tanh \left(\mathbf{W}_{z}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{z}^{2} \mathbf{x}_{t}\right) \\ \mathbf{f}_{t} &amp;=\sigma\left(\mathbf{W}_{f}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{f}^{2} \mathbf{x}_{t}\right) \\ \mathbf{o}_{t} &amp;=\sigma\left(\mathbf{W}_{o}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{o}^{2} \mathbf{x}_{t}\right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{z}_{t} &=\tanh \left(\mathbf{W}_{z}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{z}^{2} \mathbf{x}_{t}\right) \\ \mathbf{f}_{t} &=\sigma\left(\mathbf{W}_{f}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{f}^{2} \mathbf{x}_{t}\right) \\ \mathbf{o}_{t} &=\sigma\left(\mathbf{W}_{o}^{1} \mathbf{x}_{t-1}+\mathbf{W}_{o}^{2} \mathbf{x}_{t}\right) \end{aligned}
</script>
</div>
<div>
<div class="MathJax_Preview">
\begin{aligned} \mathbf{Z} &amp;=\tanh \left(\mathbf{W}_{z} * \mathbf{X}\right) \\ \mathbf{F} &amp;=\sigma\left(\mathbf{W}_{f} * \mathbf{X}\right) \\ \mathbf{O} &amp;=\sigma\left(\mathbf{W}_{o} * \mathbf{X}\right) \end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{Z} &=\tanh \left(\mathbf{W}_{z} * \mathbf{X}\right) \\ \mathbf{F} &=\sigma\left(\mathbf{W}_{f} * \mathbf{X}\right) \\ \mathbf{O} &=\sigma\left(\mathbf{W}_{o} * \mathbf{X}\right) \end{aligned}
</script>
</div>
<ul>
<li>跨通道并行性的逐元素的门控伪递归是在池化层中完成的 <span><span class="MathJax_Preview">\mathbf{h}_{t}=\mathbf{f}_{t} \odot \mathbf{h}_{t-1}+\left(1-\mathbf{f}_{t}\right) \odot \mathbf{z}_{t}</span><script type="math/tex">\mathbf{h}_{t}=\mathbf{f}_{t} \odot \mathbf{h}_{t-1}+\left(1-\mathbf{f}_{t}\right) \odot \mathbf{z}_{t}</script></span></li>
</ul>
<p><strong>Q-RNN Experiments: Language Modeling</strong></p>
<p>James Bradbury,Stephen Merity,CaimingXiong,Richard Socher (ICLR 2017) </p>
<p><img alt="1561478427867" src="../imgs/1561478427867.png" /></p>
<p><strong>Q-RNNs for Sentiment Analysis</strong></p>
<ul>
<li>通常比LSTMs更好更快</li>
<li>更加的可解释</li>
<li>例如：</li>
</ul>
<p><img alt="1561478507975" src="../imgs/1561478507975.png" /></p>
<p><strong>QRNN limitations</strong></p>
<ul>
<li>对于字符级的LMs并不像LSTMs那样有效<ul>
<li>建模时遇到的更长的依赖关系问题</li>
</ul>
</li>
<li>通常需要更深入的网络来获得与LSTM一样好的性能<ul>
<li>当它们更深入时，速度仍然更快</li>
<li>有效地使用深度作为真正递归的替代</li>
</ul>
</li>
</ul>
<h2 id="notes-08-convolutional-neural-networks">Notes 08 Convolutional Neural Networks<a class="headerlink" href="#notes-08-convolutional-neural-networks" title="Permanent link">&para;</a></h2>
<h3 id="1-cnns-convolutional-neural-networks">1 CNNs (Convolutional Neural Networks)<a class="headerlink" href="#1-cnns-convolutional-neural-networks" title="Permanent link">&para;</a></h3>
<h4 id="11-why-cnns">1.1 Why CNNs?<a class="headerlink" href="#11-why-cnns" title="Permanent link">&para;</a></h4>
<p>卷积神经网络接收词向量的序列，并首先为所有子短语创建短语向量，而不仅仅是语法正确的短语(与递归神经网络一样，将在下一组笔记中讨论)。然后，CNNs将他们分组完成手头的任务。</p>
<h4 id="12-what-is-convolution">1.2 What is Convolution?<a class="headerlink" href="#12-what-is-convolution" title="Permanent link">&para;</a></h4>
<p>我们从一维的情况开始。考虑两个一维向量 <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> 和 <span><span class="MathJax_Preview">g</span><script type="math/tex">g</script></span> ，其中 <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> 是主向量，g 是 filter。<span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> 和 <span><span class="MathJax_Preview">g</span><script type="math/tex">g</script></span> 之间的卷积，第n项处的值表示为 <span><span class="MathJax_Preview">(f * g)[n]</span><script type="math/tex">(f * g)[n]</script></span>，它等于 <span><span class="MathJax_Preview">\sum_{m=-M}^{M} f[n-m] g[m]</span><script type="math/tex">\sum_{m=-M}^{M} f[n-m] g[m]</script></span> 。</p>
<p><img alt="1561540176263" src="../imgs/1561540176263.png" /></p>
<p>上图显示了二维卷积的情况。<span><span class="MathJax_Preview">9\times9</span><script type="math/tex">9\times9</script></span> 的绿色矩阵表示关注的主矩阵 <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> 。<span><span class="MathJax_Preview">3\times3</span><script type="math/tex">3\times3</script></span> 的红色矩阵表示 filter g，当前正在计算的卷积位于位置[2,2]。图1显示了第二个表中[2,2]= 4处卷积的值。你能完成第二张表格吗?</p>
<h3 id="13-a-single-layer-cnn">1.3 A Single-Layer CNN<a class="headerlink" href="#13-a-single-layer-cnn" title="Permanent link">&para;</a></h3>
<p><img alt="1561540397352" src="../imgs/1561540397352.png" /></p>
<p>考虑单词向量 <span><span class="MathJax_Preview">x_{i} \in R^{k}</span><script type="math/tex">x_{i} \in R^{k}</script></span> 和一个n个单词的句子的单词向量串联， <span><span class="MathJax_Preview">x_{1 : n}=x_{1} \oplus x_{2} \ldots \oplus x_{n}</span><script type="math/tex">x_{1 : n}=x_{1} \oplus x_{2} \ldots \oplus x_{n}</script></span> 。最后，考虑卷积滤波器 <span><span class="MathJax_Preview">w \in R^{h k}</span><script type="math/tex">w \in R^{h k}</script></span> ，即作用于 h 个单词。对于<span><span class="MathJax_Preview">k = 2, n = 5, h = 3</span><script type="math/tex">k = 2, n = 5, h = 3</script></span>，图 2 为NLP的单层卷积层。在"the country of my birth"这个句子中，连续三个单词的每一个可能组合都将得到一个值。注意，滤波器 w 本身是一个向量，我们将有 <span><span class="MathJax_Preview">c_{i}=f\left(w^{T} x_{i : i | h-1}+b\right)</span><script type="math/tex">c_{i}=f\left(w^{T} x_{i : i | h-1}+b\right)</script></span> 来给出 <span><span class="MathJax_Preview">\mathbf{c}=\left[c_{1}, c_{2} \dots c_{n-h+1}\right] \in R^{n-h+1}</span><script type="math/tex">\mathbf{c}=\left[c_{1}, c_{2} \dots c_{n-h+1}\right] \in R^{n-h+1}</script></span> 。最后两个时间步，即从“my”或“birth”开始，我们没有足够的字向量来与滤波器相乘(因为h = 3)。如果我们需要与后两个词向量相关的卷积，一个常见的技巧是用h - 1个零向量填充句子的右边，如上图3所示。</p>
<h4 id="14-pooling">1.4 Pooling<a class="headerlink" href="#14-pooling" title="Permanent link">&para;</a></h4>
<p>假设我们不使用补零，我们将得到最终的卷积输出， <span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span> 有 <span><span class="MathJax_Preview">n-h+1</span><script type="math/tex">n-h+1</script></span> 个数。通常，我们希望接收CNN的输出，并将其作为输入，输入到更深层，如前馈神经网络或RecNN。但是，所有这些都需要一个固定长度的输入，而CNN输出的长度依赖于句子的长度 <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> 。解决这个问题的一个聪明的方法是使用max-pooling。CNN的输出 <span><span class="MathJax_Preview">\mathbf{c} \in \mathbb{R}^{n-h-1}</span><script type="math/tex">\mathbf{c} \in \mathbb{R}^{n-h-1}</script></span> 是 max-pooling 层的输入。max-pooling的输出层 <span><span class="MathJax_Preview">\hat{c}=\max \{\mathbf{c}\}</span><script type="math/tex">\hat{c}=\max \{\mathbf{c}\}</script></span> ，因此 <span><span class="MathJax_Preview">\hat{c} \in \mathbb{R}</span><script type="math/tex">\hat{c} \in \mathbb{R}</script></span> 。</p>
<p>我们也可以使用最小池化，因为通常我们使用ReLU作为非线性激活函数而ReLU的下界是0。因此，一个最小池化可能会被ReLU覆盖，所以我们几乎总是使用最大池化而不是最小池化。</p>
<h4 id="15-multiple-filters">1.5 Multiple-Filters<a class="headerlink" href="#15-multiple-filters" title="Permanent link">&para;</a></h4>
<p>在上面与图2相关的例子中，我们有 h = 2，这意味着我们只使用一个特定的组合方法，即使用过滤器来查看bi-grams。我们可以使用多个bi-grams过滤器，因为每个过滤器将学习识别不同类型的bi-grams。更一般地说，我们并不仅限于使用bi-grams，还可以使用tri-grams、 quad-grams 甚至更长的过滤器。每个过滤器都有一个关联的最大池化层。因此，CNN层的最终输出将是一个长度等于过滤器数量的向量</p>
<h4 id="16-multiple-channels">1.6 Multiple-Channels<a class="headerlink" href="#16-multiple-channels" title="Permanent link">&para;</a></h4>
<p>如果我们允许梯度流入这里使用的单词向量，那么单词向量可能会随着训练而发生显著变化。这是需要的，因为它将单词向量专门用于当前特定任务(远离GloVe初始化)。但是，如果单词只出现在测试集中而没有出现在训练集上呢？虽然出现在训练集中的其他语义相关的单词向量将从它们的起始点显著移动，但是这些单词仍将处于它们的初始点。神经网络将专门用于已更新的输入。因此，我们在使用这些单词的句子中会表现得很差。</p>
<p>一种方法是维护两组单词向量，一组“静态”(没有梯度流)和一组“动态”(通过SGD更新)。它们最初是一样的（GloVe 或者其他初始化）。这两个集合同时作为神经网络的输入。因此，初始化的词向量在神经网络的训练中始终起着重要的作用。在测试中给出看不见的单词可以提高正确理解的几率。</p>
<p>有几种处理这两个channel的方法，最常见的是在CNN中使用之前对它们进行平均。另一种方法是将CNN过滤器的长度加倍。</p>
<h4 id="17-cnn-options">1.7 CNN Options<a class="headerlink" href="#17-cnn-options" title="Permanent link">&para;</a></h4>
<p><img alt="1561541394114" src="../imgs/1561541394114.png" /></p>
<h5 id="narrow-vs-wide">Narrow vs Wide<a class="headerlink" href="#narrow-vs-wide" title="Permanent link">&para;</a></h5>
<p>参见图4。另一种问这个问题的方法是我们应该缩小还是扩大 ？即我们是否使用zero-pad ？</p>
<p>如果我们使用窄卷积，我们只在一个滤波器的所有分量都有一个匹配输入分量的位置计算卷积。在输入的开始和结束边界处显然不是这样，如图4中的左侧网络所示。</p>
<p>如果我们使用宽卷积，我们有一个输出分量对应于卷积滤波器的每个对齐。为此，我们必须在输入的开始和结束处填充 <span><span class="MathJax_Preview">h - 1</span><script type="math/tex">h - 1</script></span> 个零。</p>
<p>在窄卷积情况下，输出长度为 <span><span class="MathJax_Preview">n - h+ 1</span><script type="math/tex">n - h+ 1</script></span> ，而在宽卷积情况下，输出长度为 <span><span class="MathJax_Preview">n+h - 1</span><script type="math/tex">n+h - 1</script></span></p>
<h5 id="k-max-pooling">k-max pooling<a class="headerlink" href="#k-max-pooling" title="Permanent link">&para;</a></h5>
<p>这是对最大池化层的概括。k-max 池化层不是只从它的输入中选择最大的值，而是选择k个最大的值（并且保持原有的顺序）。设置 <span><span class="MathJax_Preview">k = 1</span><script type="math/tex">k = 1</script></span> 则是我们前面看到的最大池化层。</p>
<h2 id="reference">Reference<a class="headerlink" href="#reference" title="Permanent link">&para;</a></h2>
<p>以下是学习本课程时的可用参考书籍：</p>
<p><a href="https://item.jd.com/12355569.html">《基于深度学习的自然语言处理》</a> （车万翔老师等翻译）</p>
<p><a href="https://nndl.github.io/">《神经网络与深度学习》</a></p>
<p>以下是整理笔记的过程中参考的博客：</p>
<p><a href="https://zhuanlan.zhihu.com/p/59011576">斯坦福CS224N深度学习自然语言处理2019冬学习笔记目录</a> (课件核心内容的提炼，并包含作者的见解与建议)</p>
<p><a href="https://zhuanlan.zhihu.com/p/31977759">斯坦福大学 CS224n自然语言处理与深度学习笔记汇总</a> <span class="critic comment">这是针对note部分的翻译</span></p>
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>var disqus_config=function(){this.page.url="None",this.page.identifier="None"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//https-looperxx-github-io-my-wiki.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../CS224n-2019-10-Question%20Answering%20and%20the%20Default%20Final%20Project/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                10 Question Answering and the Default Final Project
              </div>
            </div>
          </a>
        
        
          <a href="../CS224n-2019-12-Information%20from%20parts%20of%20words%20Subword%20Models/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                12 Information from parts of words Subword Models
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 - 2020 Xiao Xu
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://github.com/looperXX" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
      </a>
    
      
      
        
        
      
      <a href="https://www.linkedin.com/in/%E5%95%B8-%E5%BE%90-012456163/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.77e55a48.min.js"></script>
      <script src="../assets/javascripts/bundle.9554a270.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: ['navigation.tabs', 'header.autohide'],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="../js/baidu-tongji.js"></script>
      
    
  </body>
</html>