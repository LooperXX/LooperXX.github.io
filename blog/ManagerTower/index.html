<!DOCTYPE html><html class=no-js lang=zh> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="Xiao Xu - Homepage" name=description><meta content="Xiao Xu" name=author><link href=https://looperxx.github.io/blog/ManagerTower/ rel=canonical><link href=../.. rel=prev><link href=../BridgeTower/ rel=next><link href=../../assets/images/favicon.png rel=icon><meta content="mkdocs-1.4.2, mkdocs-material-9.1.6" name=generator><title>ACL 2023 Oral Paper | ManagerTower: 自适应融合单模态专家见解的视觉语言表示学习方法 - The Sun Also Rises.</title><link href=../../assets/stylesheets/main.ded33207.min.css rel=stylesheet><link href=../../assets/stylesheets/palette.a0c5b2b5.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-CV5JZHXZY8"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-CV5JZHXZY8",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-CV5JZHXZY8",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                .gdesc-inner { font-size: 0.75rem; }
                body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
                body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
                body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
                </style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#0-take-away-messages> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav aria-label=页眉 class="md-header__inner md-grid"> <a aria-label="The Sun Also Rises." class="md-header__button md-logo" data-md-component=logo href=../.. title="The Sun Also Rises."> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> The Sun Also Rises. </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> ACL 2023 Oral Paper | ManagerTower: 自适应融合单模态专家见解的视觉语言表示学习方法 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=indigo data-md-color-media data-md-color-primary=indigo data-md-color-scheme=default id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_2 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media data-md-color-primary=indigo data-md-color-scheme=slate id=__palette_2 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=搜索 autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=搜索 required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label=查找 class=md-search__options> <a aria-label=分享 class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=分享> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"></path></svg> </a> <button aria-label=清空当前内容 class="md-search__icon md-icon" tabindex=-1 title=清空当前内容 type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/LooperXX/LooperXX.github.io title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class=md-source__repository> LooperXX/LooperXX.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav aria-label=标签 class=md-tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a class=md-tabs__link href=../..> Xiao Xu @ HIT-SCIR </a> </li> <li class=md-tabs__item> <a href=./ class="md-tabs__link md-tabs__link--active"> Blogs </a> </li> <li class=md-tabs__item> <a href=../../notes/Normalization/ class=md-tabs__link> Notes </a> </li> <li class=md-tabs__item> <a href=../../notes/CS224n-2019-00-Info/ class=md-tabs__link> Notes on CS224n-2019 </a> </li> <li class=md-tabs__item> <a href=../../notes/MkDocs_demo/ class=md-tabs__link> Notes on MkDocs </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航栏 class="md-nav md-nav--primary md-nav--lifted" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="The Sun Also Rises." class="md-nav__button md-logo" data-md-component=logo href=../.. title="The Sun Also Rises."> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> The Sun Also Rises. </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/LooperXX/LooperXX.github.io title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class=md-source__repository> LooperXX/LooperXX.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../..> Xiao Xu @ HIT-SCIR </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked class="md-nav__toggle md-toggle" id=__nav_2 type=checkbox> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> Blogs <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=true aria-labelledby=__nav_2_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> ACL 2023 Oral Paper | ManagerTower: 自适应融合单模态专家见解的视觉语言表示学习方法 <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> ACL 2023 Oral Paper | ManagerTower: 自适应融合单模态专家见解的视觉语言表示学习方法 </a> <nav aria-label=目录 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#0-take-away-messages> 0. Take-away messages </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#1> 1. 背景与动机 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#2> 2. 模型架构 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#3-manager> 3. Manager 的设计 </a> <nav aria-label="3. Manager 的设计" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#31-sae-manager> 3.1 静态聚合专家的 SAE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#32-saue-manager> 3.2 静态聚合单模态专家的 SAUE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#33-aaue-manager> 3.3 自适应聚合单模态专家的 AAUE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#34-manager> 3.4 不同Manager的性能比较 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#4> 4. 实验效果 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#5> 5. 可视化结果 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#6> 6. 结论 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#7> 7. 附录 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../BridgeTower/ class=md-nav__link> AAAI 2023 Oral Paper | BridgeTower: 在视觉语言表示学习中建立编码器间的桥梁 </a> </li> <li class=md-nav__item> <a href=../Profile%20SLU/ class=md-nav__link> AAAI 2022 Oral Paper | Profile SLU: 基于Profile信息的口语语言理解基准 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> Notes <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notes/Normalization/ class=md-nav__link> Normalization </a> </li> <li class=md-nav__item> <a href=../../notes/Transfer%20Learning/ class=md-nav__link> Transfer Learning </a> </li> <li class=md-nav__item> <a href=../../notes/Attention/ class=md-nav__link> Attention </a> </li> <li class=md-nav__item> <a href=../../notes/Neural%20Reading%20Comprehension%20and%20beyond/ class=md-nav__link> Machine Reading Comprehension </a> </li> <li class=md-nav__item> <a href=../../notes/Notes%20on%20NCRF%2B%2B/ class=md-nav__link> NCRF++ </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_4 type=checkbox> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> Notes on CS224n-2019 <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_4_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Notes on CS224n-2019 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notes/CS224n-2019-00-Info/ class=md-nav__link> CS224n-2019 Introduction </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-Assignment/ class=md-nav__link> CS224n-2019 Assignment </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-01-Introduction%20and%20Word%20Vectors/ class=md-nav__link> 01 Introduction and Word Vectors </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-02-Word%20Vectors%202%20and%20Word%20Senses/ class=md-nav__link> 02 Word Vectors 2 and Word Senses </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-03-Word%20Window%20Classification%2CNeural%20Networks%2C%20and%20Matrix%20Calculus/ class=md-nav__link> 03 Word Window Classification,Neural Networks, and Matrix Calculus </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-04-Backpropagation%20and%20Computation%20Graphs/ class=md-nav__link> 04 Backpropagation and Computation Graphs </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-05-Linguistic%20Structure%20Dependency%20Parsing/ class=md-nav__link> 05 Linguistic Structure Dependency Parsing </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-06-The%20probability%20of%20a%20sentence%20Recurrent%20Neural%20Networks%20and%20Language%20Models/ class=md-nav__link> 06 The probability of a sentence Recurrent Neural Networks and Language Models </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-07-Vanishing%20Gradients%20and%20Fancy%20RNNs/ class=md-nav__link> 07 Vanishing Gradients and Fancy RNNs </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-08-Machine%20Translation%2C%20Sequence-to-sequence%20and%20Attention/ class=md-nav__link> 08 Machine Translation, Sequence-to-sequence and Attention </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-09-Practical%20Tips%20for%20Final%20Projects/ class=md-nav__link> 09 Practical Tips for Final Projects </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-10-Question%20Answering%20and%20the%20Default%20Final%20Project/ class=md-nav__link> 10 Question Answering and the Default Final Project </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-11-ConvNets%20for%20NLP/ class=md-nav__link> 11 ConvNets for NLP </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-12-Information%20from%20parts%20of%20words%20Subword%20Models/ class=md-nav__link> 12 Information from parts of words Subword Models </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-13-Modeling%20contexts%20of%20use%20Contextual%20Representations%20and%20Pretraining/ class=md-nav__link> 13 Modeling contexts of use Contextual Representations and Pretraining </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-14-Transformers%20and%20Self-Attention%20For%20Generative%20Models/ class=md-nav__link> 14 Transformers and Self-Attention For Generative Models </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-15-Natural%20Language%20Generation/ class=md-nav__link> 15 Natural Language Generation </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-16-Coreference%20Resolution/ class=md-nav__link> 16 Coreference Resolution </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-17-Multitask%20Learning/ class=md-nav__link> 17 Multitask Learning </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-18-Tree%20Recursive%20Neural%20Networks%2C%20Constituency%20Parsing%2C%20and%20Sentiment/ class=md-nav__link> 18 Tree Recursive Neural Networks, Constituency Parsing, and Sentiment </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-19-Safety%2C%20Bias%2C%20and%20Fairness/ class=md-nav__link> 19 Safety, Bias, and Fairness </a> </li> <li class=md-nav__item> <a href=../../notes/CS224n-2019-20-The%20Future%20of%20NLP%20%2B%20Deep%20Learning/ class=md-nav__link> 20 The Future of NLP + Deep Learning </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_5 type=checkbox> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> Notes on MkDocs <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_5_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Notes on MkDocs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notes/MkDocs_demo/ class=md-nav__link> Demo </a> </li> <li class=md-nav__item> <a href=../../notes/Material%20Theme%20Tutorial/ class=md-nav__link> Material Theme Tutorial </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=目录 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#0-take-away-messages> 0. Take-away messages </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#1> 1. 背景与动机 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#2> 2. 模型架构 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#3-manager> 3. Manager 的设计 </a> <nav aria-label="3. Manager 的设计" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#31-sae-manager> 3.1 静态聚合专家的 SAE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#32-saue-manager> 3.2 静态聚合单模态专家的 SAUE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#33-aaue-manager> 3.3 自适应聚合单模态专家的 AAUE Manager </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#34-manager> 3.4 不同Manager的性能比较 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#4> 4. 实验效果 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#5> 5. 可视化结果 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#6> 6. 结论 </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#7> 7. 附录 </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>ACL 2023 Oral Paper | ManagerTower: 自适应融合单模态专家见解的视觉语言表示学习方法</h1> <div class="admonition note"> <p class=admonition-title>ManagerTower: Aggregating the Insights of Uni-Modal Experts for Vision-Language Representation Learning</p> <p><strong>Xiao Xu</strong>, Bei Li, Chenfei Wu, Shao-Yen Tseng, Anahita Bhiwandiwalla, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.</p> <p><a href=https://2023.aclweb.org/ >ACL 2023 (Oral)</a> | Association for Computational Linguistics</p> <p><span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 9V3.5L18.5 9M6 2c-1.11 0-2 .89-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6H6Z"></path></svg></span> <a href=https://aclanthology.org/2023.acl-long.811/ >Paper</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M16.318 8.465V9.59h1.344V8.465zm-6.9.228 2.059 3.412-2.155 3.311h1.14l1.563-2.41 1.46 2.41h1.628l-2.136-3.553 2.056-3.17h-1.125l-1.484 2.264-1.371-2.264zm-.096 6.723H9.32v.004zM2.25 10.314a5.039 5.039 0 0 0-1.814.348v.926a3.32 3.32 0 0 1 1.593-.445c.59 0 .883.258.883.775v.455h-.355c-.822.001-1.453.152-1.893.451a1.456 1.456 0 0 0-.663 1.278 1.382 1.382 0 0 0 .408 1.033 1.48 1.48 0 0 0 1.065.398c.517 0 .998-.217 1.443-.652l.004.002h.053c.159.435.512.652 1.066.652a2.757 2.757 0 0 0 .754-.129l-.031-.756a.803.803 0 0 1-.176.022c-.254 0-.377-.192-.377-.584v-2.215c.001-1.038-.653-1.559-1.961-1.559zm6.646 0c-.713 0-1.246.353-1.591 1.057v-.941H5.959v4.99h1.346v-3.178c.336-.535.768-.805 1.306-.805a1.607 1.607 0 0 1 .534.104v-1.2a1.408 1.408 0 0 0-.249-.027zm7.422.116v4.994l1.344-.004v-4.99zm2.52 0 1.902 4.99h1.332L24 10.43h-.965l-1.385 3.6-1.396-3.6zM2.596 13.145h.322v1.013c-.331.305-.651.46-.982.455a.643.643 0 0 1-.643-.65c0-.543.433-.818 1.303-.818z"></path></svg></span> <a href=https://arxiv.org/abs/2306.00103>Arxiv</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33.85 0 1.71.11 2.5.33 1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"></path></svg></span> <a href=https://github.com/LooperXX/ManagerTower>Code</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12.6 12.3h-2v3.2h2.1c.6 0 .9-.2 1.2-.5.3-.3.4-.6.4-1.1 0-.5-.1-.8-.4-1.1-.3-.3-.7-.5-1.3-.5M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6m1.2 14c-.6.5-1.1.7-2.4.7h-2.2V20H9v-9h3.8c1.3 0 1.9.3 2.4.8.6.6.8 1.2.8 2.1 0 .9-.2 1.6-.8 2.1M13 9V3.5L18.5 9H13Z"></path></svg></span> <a href=./files/ManagerTower-ACL23-PPT-2023-06-EN-12min.pdf>Slides</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4Z"></path></svg></span> <a href=https://youtu.be/SOHprfiiClQ>Video(EN)</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4Z"></path></svg></span> <a href=https://www.bilibili.com/video/BV17s4y1y7Ny>Video(CN)</a> | <span class=twemoji><svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m15.54 3.5 4.96 4.97-1.43 1.41-4.95-4.95 1.42-1.43M3.5 19.78l6.5-6.47c-.1-.31-.03-.7.23-.96.39-.39 1.03-.39 1.42 0 .39.4.39 1.03 0 1.42-.26.26-.65.33-.96.23l-6.47 6.5 10.61-3.55 3.53-6.36-4.94-4.95-6.37 3.53L3.5 19.78Z"></path></svg></span> <a href=http://looperxx.github.io/blog/ManagerTower>Blog(CN)</a> | <span class=twemoji><svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></span> <a href=https://twitter.com/looperxx27/status/1678341890809401346>Tweet(EN)</a></p> </div> <h2 id=0-take-away-messages>0. Take-away messages<a class=headerlink href=#0-take-away-messages title="Permanent link">¶</a></h2> <ul> <li>提出了一个<strong>简单有效</strong>的视觉语言模型架构，ManagerTower，通过在每个跨模态层中引入Manager，从而<strong>自适应</strong>地聚合<strong>不同层次</strong>的预训练单模态专家的<strong>Insight</strong>，针对不同样本中的不同令牌，<strong>灵活</strong>地生成<strong>不同</strong>的聚合权重，促进更全面的跨模态对齐和融合。</li> <li>通过交叉注意力机制融合之前跨模态层的输出表示，从而得到跨模态融合查询，进一步帮助Manager<strong>正确</strong>聚合<strong>当前</strong>跨模态层<strong>所需</strong>的单模态语义知识。</li> <li>在<strong>公平</strong>的评估设置下，与Two-Tower架构的METER模型以及BridgeTower架构相比，ManagerTower<strong>显著</strong>地提高了模型的多模态表示能力。</li> <li><strong>仅</strong>使用400万张图片进行视觉语言预训练，ManagerTower在各种视觉语言下游任务上取得了十分<strong>强大</strong>的性能，击败了许多用<strong>更多</strong>数据和参数进行预训练的强大模型。</li> <li>ManagerTower可以<strong>适用</strong>于不同的视觉、文本或跨模态编码器。</li> </ul> <h2 id=1>1. 背景与动机<a class=headerlink href=#1 title="Permanent link">¶</a></h2> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/bridgetower-examples.png><img alt=examples src=../imgs/bridgetower-examples.png></a></p> <blockquote> <p>图源：<a href=https://arxiv.org/abs/1912.02315>12-in-1: Multi-Task Vision and Language Representation Learning</a></p> </blockquote> <p>视觉语言研究的目标，是训练一个能够理解图像和文本的智能AI系统。 上图展示了一些流行的视觉语言任务。视觉问答是其中最著名的任务之一，它需要根据输入图像来回答和图片相关的问题。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-two-tower.jpg><img alt=brief-two-tower src=../imgs/managertower-brief-two-tower.jpg></a></p> <p>自2019年以来，在大规模图像-文本对的自监督预训练的帮助下，基于Transformer的视觉语言模型取得了显著的进展。 从模型架构的角度来看，近期工作可以看作是由三个模块组成的双塔架构，即文本编码器、视觉编码器，以及在它们之上的跨模态编码器。 如果我们深入双塔结构的单模态编码器中，例如<a href=https://arxiv.org/abs/2211.10797>METER</a>模型。 我们可以发现他们只将最后一层的单模态特征直接送入顶部的跨模态编码器，忽略了深层单模态编码器中不同层次的语义信息。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-two-tower-vs-bridgetower.jpg><img alt=brief-two-tower-vs-bridgetower src=../imgs/managertower-brief-two-tower-vs-bridgetower.jpg></a></p> <p>不同于双塔结构，BridgeTower将多个顶部单模态层与每个跨模态层逐层连接，以利用不同层次的单模态语义知识。</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-bridgetower-vs-managertower.jpg><img alt=brief-two-tower-vs-bridgetower src=../imgs/managertower-brief-bridgetower-vs-managertower.jpg width=500></a></p> </figure> <p>但是 BridgeTower 仍然存在两个显著缺陷，限制了它对单模态表示的高效利用。</p> <ul> <li>首先，它对不同单模态层表示的逐层利用是<strong>低效</strong>的。每个跨模态层只能利用<strong>人为指定</strong>的某一单模态层表示，因此<strong>限制</strong>了其对不同层次的单模态语义知识的利用。</li> <li>其次，跨模态层的数量与它所使用的单模态层表示的数量是<strong>绑定</strong>在一起的，因此限制了其<strong>可扩展性</strong>和<strong>能力</strong>。</li> </ul> <p>我们在BridgeTower的基础上，对以上两个方面加以改进，并提出了名为ManagerTower的新颖的VL模型架构。 每个Manager(管理者)将多层单模态表示视为<strong>不同层次</strong>的预训练单模态专家的<strong>Insight</strong>(洞察力)。 ManagerTower能够通过每个跨模态层的Manager<strong>自适应</strong>地聚合Insight。</p> <h2 id=2>2. 模型架构<a class=headerlink href=#2 title="Permanent link">¶</a></h2> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-framework.jpg><img alt=framework src=../imgs/managertower-framework.jpg></a></p> <p>这里我们展示了ManagerTower的详细架构图。 具体而言，我们使用RoBERTa Base和CLIP-ViT Base作为单模态编码器。 跨模态编码器为6层，在每个跨模态层中引入了Manager，以聚合<strong>不同层次</strong>的预训练单模态专家的<strong>Insight</strong>。</p> <p>Manager可以<strong>自适应</strong>地利用<strong>不同层次</strong>的单模态语义知识，，针对不同样本中的不同令牌，<strong>灵活</strong>地生成<strong>不同</strong>的聚合权重，促进更全面的跨模态对齐和融合。 需要注意的是，ManagerTower架构<strong>适用</strong>于不同的视觉、文本或跨模态编码器。</p> <h2 id=3-manager>3. Manager 的设计<a class=headerlink href=#3-manager title="Permanent link">¶</a></h2> <h3 id=31-sae-manager>3.1 静态聚合专家的 SAE Manager<a class=headerlink href=#31-sae-manager title="Permanent link">¶</a></h3> <p>在Layer Fusion(层融合)方法的启发下，我们采用并调整了<a href=https://arxiv.org/abs/1906.01787>层线性组合</a>的方法，通过可学习的权重将之前所有的单模态和跨模态层表示聚合起来。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-equation-1.png><img alt=managertower-brief-equation-1 src=../imgs/managertower-brief-equation-1.png></a></p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-comparison-1.png><img alt=managertower-brief-comparison-1 src=../imgs/managertower-brief-comparison-1.png width=400></a></p> </figure> <p>我们称之为静态聚合专家的SAE Manager。 上图简要地显示了BridgeTower和SAE Manager的计算流程以及结构对比。 这里的 <span class=arithmatex>\(\ell\)</span> 表示跨模态层的编号。然而，与BridgeTower相比，其性能增益仍然是有限的。</p> <p>接着我们计算每两个<strong>连续</strong>的文本/视觉Manager之间聚合的单模态/跨模态表示的余弦相似度，以进一步分析SAE Manager是如何聚合Insight的。</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-cosine-similarity-sae.png><img alt=managertower-cosine-similarity-sae src=../imgs/managertower-cosine-similarity-sae.png width=600></a></p> </figure> <p>如上图所示，SAE的单模态聚合表示的相似度总是接近<strong>1</strong>，而跨模态的相似度随着深度的增加而增加，越来越接近于<strong>1</strong>。这表明，在不同的SAE Manager中，聚合的单模态表示几乎是<strong>相同</strong>的，而聚合的跨模态表示随着深度的增加而变得<strong>相似</strong>。</p> <p>我们假设，由于不同的SAE Manager为每个跨模态层提供<strong>相似</strong>的聚合单模态表示，这使得<strong>更多</strong>的之前跨模态层的输出表示，可能会带来<strong>混淆</strong>Manager的<strong>过多冗余</strong>信息。 因此，我们认为应当聚焦于所有单模态层表示和前一个跨模态层表示。</p> <h3 id=32-saue-manager>3.2 静态聚合单模态专家的 SAUE Manager<a class=headerlink href=#32-saue-manager title="Permanent link">¶</a></h3> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-equation-2.png><img alt=managertower-brief-equation-2 src=../imgs/managertower-brief-equation-2.png></a></p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-comparison-2.png><img alt=managertower-brief-comparison-2 src=../imgs/managertower-brief-comparison-2.png width=400></a></p> </figure> <p>我们称之为静态聚合单模态专家的SAUE Manager。 上图简要地显示了SAE和SAUE Manager的计算流程以及结构对比。</p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-cosine-similarity-sae-vs-saue.png><img alt=managertower-cosine-similarity-sae-vs-saue src=../imgs/managertower-cosine-similarity-sae-vs-saue.png width=600></a></p> </figure> <p>有趣的是，SAUE的跨模态聚合表示的相似度会随着深度的增加而<strong>降低</strong>。 这表明随着深度的增加，SAUE可以聚合得到更全面和<strong>可区分</strong>的跨模态表示。 与BridgeTower相比，明显改善的结果也进一步证明了我们的假设。</p> <p>然而，SAUE仍然存在两个问题：</p> <ul> <li>首先，聚合的单模态表示在不同的Manager之间<strong>仍然</strong>是<strong>几乎相同</strong>的，这与<strong>跨模态层之间</strong>对单模态语义知识的需求是<strong>不同</strong>的的直觉不一致； </li> <li>第二，在推理阶段，Manager将训练阶段学到的<strong>相同权重</strong>应用于<strong>不同</strong>样本中的<strong>所有</strong>令牌，以聚合单模态专家的Insight，这与对单模态语义知识的需求在<strong>令牌之间</strong>以及<strong>样本之间</strong>是<strong>不同</strong>的的直觉不一致。</li> </ul> <h3 id=33-aaue-manager>3.3 自适应聚合单模态专家的 AAUE Manager<a class=headerlink href=#33-aaue-manager title="Permanent link">¶</a></h3> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-equation-3.png><img alt=managertower-brief-equation-3 src=../imgs/managertower-brief-equation-3.png></a></p> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-brief-comparison-3.png><img alt=managertower-brief-comparison-3 src=../imgs/managertower-brief-comparison-3.png width=400></a></p> </figure> <p>为了解决上述局限性，我们提出了自适应聚合单模态专家的AAUE Manager。 上图简要地显示了SAUE和AAUE Manager的计算流程以及结构对比。 AAUE将输入的跨模态部分作为视觉/文本查询(Query)，从而生成聚合权重。</p> <p>从聚合权重的角度来看：</p> <ul> <li>之前的SAE和SAUE Manager是<strong>静态</strong>的<strong>句子级M</strong>anager，对不同样本中的所有令牌共享<strong>相同</strong>的、在训练阶段学习到的可聚合权重。</li> <li>相比之下，AAUE Manager是<strong>自适应</strong>的<strong>令牌级</strong>Manager，它为不同样本中的不同令牌<strong>自适应</strong>地生成<strong>不同</strong>的聚合权重。因此，AAUE可以在<strong>训练</strong>和<strong>推理</strong>阶段<strong>自适应</strong>地利用预训练单模态专家的<strong>不同层次</strong>的单模态语义知识。</li> </ul> <h3 id=34-manager>3.4 不同Manager的性能比较<a class=headerlink href=#34-manager title="Permanent link">¶</a></h3> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-results-managers.png><img alt=managertower-results-managers src=../imgs/managertower-results-managers.png width=500></a></p> </figure> <p>上表中显示了不同类型的Manager和不同Query在VQAv2和Flickr30K数据集上的表现。</p> <p>为了帮助每个跨模态层的Manager更好地利用单模态的语义知识，我们使用Cross-Attention机制，来利用文本查询丰富视觉查询，从而得到跨模态的融合查询，这可以更好地帮助Manager<strong>正确</strong>地聚合<strong>当前</strong>跨模态层<strong>所需</strong>的单模态语义知识。 在跨模态融合查询的帮助下，AAUE Manager在两个数据集上都取得了大大优于其他Manager的性能。</p> <h2 id=4>4. 实验效果<a class=headerlink href=#4 title="Permanent link">¶</a></h2> <figure> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/bridgetower-pre-train-data.png><img alt="Pre-train Data" src=../imgs/bridgetower-pre-train-data.png width=350></a></p> </figure> <p>我们基于公共图文对数据集对BridgeTower进行预训练，如上表所示，大约共计400万张独立图片，900万对图文对。 我们使用通用的掩码语言建模 (Masked Language Modeling, MLM) 和图文匹配 (Image-Text Matching, ITM) 任务作为预训练任务。 所有的预训练设置与预训练参数都与METER和BridgeTower<strong>一致</strong>，以提供ManagerTower与METER和BridgeTower之间的<strong>公平比较</strong>。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-results.png><img alt=managertower-results src=../imgs/managertower-results.png></a></p> <p>仅利用 400w 张独立图像进行视觉语言预训练，ManagerTower在各种下游的视觉语言任务上取得了卓越的表现。尤其是，METER、BridgeTower和ManagerTower使用<strong>相同</strong>的预训练和微调设置，而ManagerTower<strong>显著</strong>提高了下游性能，特别是在VQAv2 Test-Std上取得了<strong>79.15</strong>%的准确率。</p> <p>这进一步表明，在所有其他因素固定的情况下，与为METER引入Bridge的BridgeTower相比， ManagerTower通过精心设计的Manager，能够更有效地利用不同层次的单模态语义知识。</p> <p>值得注意的是，ManagerTower不仅超过了许多在4M数据上预训练的base模型，而且还超过了一些用<strong>更多</strong>数据或参数训练的大模型。</p> <h2 id=5>5. 可视化结果<a class=headerlink href=#5 title="Permanent link">¶</a></h2> <p>我们通过对VQAv2验证集上的所有样本，可视化每个跨模态层的文本或视觉Manager的平均聚合权重，来深入研究Manager是如何聚合Insight的。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-visualization-aggregation-weights-saue.png><img alt=managertower-visualization-aggregation-weights-saue src=../imgs/managertower-visualization-aggregation-weights-saue.png></a></p> <p>上图展示了SAUE Manager的聚合权重分布。其中，X轴表示单模态专家的编号，图例表示跨模态层的编号。 不管是文本行还是视觉行，不同跨模态层的SAUE Manager都有<strong>类似</strong>的<strong>渐进</strong>趋势，这与我们对SAUE Manager的单模态聚合表示之间的余弦相似度的观察是<strong>一致</strong>的。</p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=100% href=../imgs/managertower-visualization-aggregation-weights-pre-trained-aaue.png><img alt=managertower-visualization-aggregation-weights-pre-trained-aaue src=../imgs/managertower-visualization-aggregation-weights-pre-trained-aaue.png></a></p> <p>有趣的是，对于AAUE Manager来说，Manager生成的聚合权重分布与BridgeTower中人为指定的独热分布完全不同，而且有两个不同的趋势：</p> <ul> <li>在垂直方向上，文本和视觉Manager之间存在着<strong>明显</strong>的差异。</li> <li>在水平方向上，无论是文本Manager还是视觉Manager，他们在不同的跨模态层都表现出非常<strong>不同</strong>的聚合权重分布。</li> </ul> <p>这有力地证明了AAUE Manager能够<strong>自适应</strong>地利用<strong>不同层次</strong>的单模态语义知识进行<strong>全面</strong>的跨模态表示学习。</p> <h2 id=6>6. 结论<a class=headerlink href=#6 title="Permanent link">¶</a></h2> <p>在本文中，我们提出了ManagerTower，它通过在每个跨模态层中引入Manager，从而<strong>自适应</strong>地聚合<strong>不同层次</strong>的预训练单模态专家的<strong>Insight</strong>，针对不同样本中的不同令牌，<strong>灵活</strong>地生成<strong>不同</strong>的聚合权重，促进更全面的跨模态对齐和融合。 通过交叉注意力机制融合之前跨模态层的输出表示，从而得到跨模态融合查询，进一步帮助Manager<strong>正确</strong>聚合<strong>当前</strong>跨模态层<strong>所需</strong>的单模态语义知识。</p> <p><strong>仅</strong>利用400万张独立图像进行视觉语言预训练，ManagerTower在各种下游的视觉语言任务上取得了卓越的表现。尤其是，METER、BridgeTower和ManagerTower使用<strong>相同</strong>的预训练和微调设置，而ManagerTower<strong>显著</strong>提高了下游性能，特别是在VQAv2 Test-Std上取得了<strong>79.15</strong>%的准确率，在Flickr30K上的取得了<strong>86.56</strong>%IR@1和<strong>95.64</strong>%TR@1的效果。</p> <h2 id=7>7. 附录<a class=headerlink href=#7 title="Permanent link">¶</a></h2> <p>我们在附录中给出了更加<strong>丰富</strong>的实验结果与分析，包括：</p> <ul> <li>ManagerTower和BridgeTower模型的<strong>参数量</strong>、<strong>计算量</strong>、<strong>推理时间</strong>和下游任务性能的详细比较与分析</li> <li>ManagerTower中不同类型的Manager的聚合权重分布的可视化结果</li> <li>ManagerTower的预训练和下游任务微调的详细参数配置</li> <li>......</li> </ul> <p>欢迎感兴趣的同学阅读我们的论文。</p> </article> </div> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2019 - 2022; Xiao Xu </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ rel=noopener target=_blank> Material for MkDocs </a> </div> <div class=md-social> <a class=md-social__link href=https://github.com/looperXX rel=noopener target=_blank title=github.com> <svg viewbox="0 0 480 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg> </a> <a class=md-social__link href=https://twitter.com/looperxx_nlp rel=noopener target=_blank title=twitter.com> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg> </a> <a class=md-social__link href=https://www.linkedin.com/in/%E5%95%B8-%E5%BE%90-012456163/ rel=noopener target=_blank title=www.linkedin.com> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.tooltips", "navigation.indexes", "navigation.tracking", "navigation.sections", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.51198bba.min.js></script> <script src=../../javascripts/baidu-tongji.js></script> <script src=../../javascripts/mathjax.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body> </html>